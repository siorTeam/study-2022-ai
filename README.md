# 2022 AI  

SIOR 2022년 AI 스터디  

## 강의  
http://hunkim.github.io/ml/  
https://deeplearningzerotoall.github.io/season2/lec_tensorflow.html  
  
Github: https://github.com/deeplearningzerotoall/TensorFlow  
YouTube: http://bit.ly/2HHrybT  
Slide: http://bit.ly/2LQMKvk  

## 방식:
1명 주도 토론 (1명은 로테이션)  

## 일정:
일주일에 1번 목요일 21:00~23:00  

### [4/21: 황찬욱](/Weekly%20Summary/AI_STUDY_1%EC%A3%BC%EC%B0%A8.pdf)  
Lec 01: 기본적인 Machine Learning 의 용어와 개념 설명  
Lec 02: Simple Linear Regression  
Lab 02: Simple Linear Regression 를 TensorFlow 로 구현하기  
Lec 03: Linear Regression and How to minimize cost  
Lab 03: Linear Regression and How to minimize cost 를 TensorFlow 로 구현하기  
Lec 04: Multi-variable Linear Regression  
Lab 04: Multi-variable Linear Regression를 TensorFlow 로 구현하기  

### [4/28: 박창민](/Weekly%20Summary/AI_STUDY_2%EC%A3%BC%EC%B0%A8.pdf)
Lec 05-1: Logistic Regression/Classification 의 소개  
Lec 05-2: Logistic Regression/Classification 의 cost 함수, 최소화  
Lab 05-3: Logistic Regression/Classification 를 TensorFlow 로 구현하기  
Lec 06-1: Softmax Regression: 기본 개념소개  
Lec 06-2: Softmax Classifier의 cost함수  
Lab 06-1: Softmax classifier 를 TensorFlow 로 구현하기  
Lab 06-2: Fancy Softmax classifier 를 TensorFlow 로 구현하기  

### [5/5: 강오령](/Weekly%20Summary/AI_STUDY_3%EC%A3%BC%EC%B0%A8.pdf)  
Lab 07-1: Application & Tips: 학습률(Learning Rate)과 데이터 전처리(Data Preprocessing)  
Lab 07-2-1: Application & Tips: 오버피팅(Overfitting) & Solutions  
Lab 07-2-2: Application & Tips: 학습률, 전처리, 오버피팅을 TensorFlow 로 실습  
Lab 07-3-1: Application & Tips: Data & Learning  
Lab 07-3-2: Application & Tips: 다양한 Dataset 으로 실습  

### [5/12: 이승민](/Weekly%20Summary/AI_STUDY_4%EC%A3%BC%EC%B0%A8.pdf)  
Lec 08-1: 딥러닝의 기본 개념: 시작과 XOR 문제  
Lec 08-2: 딥러닝의 기본 개념2: Back-propagation 과 2006/2007 ‘딥’의 출현  
Lec 09-1: XOR 문제 딥러닝으로 풀기  
Lec 09-2: 딥넷트웍 학습 시키기 (backpropagation)  
Lab 09-1: Neural Net for XOR  
Lab 09-2: Tensorboard (Neural Net for XOR)  

### [5/19: 황찬욱](/Weekly%20Summary/AI_STUDY_5%EC%A3%BC%EC%B0%A8.pdf)  
Lab 10-1: Sigmoid 보다 ReLU가 더 좋아  
Lab 10-2: Weight 초기화 잘해보자d  
Lab 10-3: Dropout  
Lab 10-4: Batch Normalization  

### [6/24: 박창민](/Weekly%20Summary/AI_STUDY_6%EC%A3%BC%EC%B0%A8.pdf)  
Lec 11-1: ConvNet의 Conv 레이어 만들기  
Lec 11-2: ConvNet Max pooling 과 Full Network  
Lec 11-3: ConvNet의 활용예  
Lab 11-0-1: CNN Basic: Convolution  
Lab 11-0-2: CNN Basic: Pooling  
Lab 11-2: mnist cnn keras functional eager  
Lab 11-1: mnist cnn keras sequential eager  
Lab-11-3: mnist cnn keras subclassing eager  
Lab-11-4: mnist cnn keras ensemble eager  
Lab-11-5: mnist cnn best keras eager  
 
### 7/00: 뒤풀이






## 대회

https://dacon.io/competitions/official/235902/overview/description

모델링 설계 경험과 대회 참여 목적

첫 미팅 일자: 7월 8일 PM 09:00(1시간예상)

- 미니 프로젝트 진행 사항 얘기
- ENV: colab

gitlab의 프로젝트로 폴더 공유, 
`project/`폴더 아래에 각자 브랜치 생성 후(예를들어, `sub-pcm`),
알아서 관리(폴더내)

### 연습 프로젝트

1. 심리 성향 예측 AI 경진대회

> https://dacon.io/competitions/official/235647/data

base line code
> https://dacon.io/competitions/official/235647/codeshare/1699?page=1&dtype=recent

2. 한국어 글자체 이미지 데이터

> https://aihub.or.kr/aidata/133
